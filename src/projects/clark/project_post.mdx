import {
    Grid,
    ImageList,
    ImageListItem,
} from '@mui/material';

import TeamMemberCard from "src/components/TeamMemberCard";

import image1 from "./assets/post/PaperPrototype1.jpg";
import image2 from "./assets/post/PaperPrototype2.jpg";
import image3 from "./assets/post/PaperPrototype3.jpg";
import image4 from "./assets/post/PaperPrototype4.jpg";
import image5 from "./assets/post/PaperPrototype5.jpg";
import image6 from "./assets/post/PaperPrototype6.jpg";

import task1Step1Image1 from "./assets/post/splash.png";
import task1Step1Image2 from "./assets/post/login.png";

import task1Step2Image1 from "./assets/post/present.png";
import task1Step2Image2 from "./assets/post/welcome.png";
import task1Step2Image3 from "./assets/post/viewpreview.png";
import task1Step2Image4 from "./assets/post/edit_clark.png";

import task1Step3Image1 from "./assets/post/stop.png";
// TODO: I understand image missing.
import task1Step3Image2 from "./assets/post/dont_understand.png";
import task1Step3Image3 from "./assets/post/ask_question.png";
import task1Step3Image4 from "./assets/post/submitted_question.png";
import task1Step3Image5 from "./assets/post/view_clark.png";

import task1Step4Image1 from "./assets/post/end_recording.png";
import task1Step4Image2 from "./assets/post/end_presentation.png";
import task2Step2Image1 from "./assets/post/view_recordings.png";


import pathPhotoAnna from "./assets/team/anna.jpg";
import pathPhotoDonavan from "./assets/team/donavan.jpg";
import pathPhotoJesse from "./assets/team/jesse.jpg";
import pathPhotoJudy from "./assets/team/judy.jpg";
import pathPhotoYunwei from "./assets/team/yunwei.jpg";


# Clark - Presenting Made Easier

## Team Members

<Grid container spacing={4}>
    <Grid item>
        <TeamMemberCard name="Anna Shih" photo={pathPhotoAnna} />
    </Grid>

    <Grid item>
        <TeamMemberCard name="Donavan See" photo={pathPhotoDonavan} />
    </Grid>

    <Grid item>
        <TeamMemberCard name="Jesse Hu" photo={pathPhotoJesse}  />
    </Grid>

    <Grid item>
        <TeamMemberCard name="Judy Pham" photo={pathPhotoJudy}/>
    </Grid>
    <Grid item>
        <TeamMemberCard name="Yunwei Liang" photo={pathPhotoYunwei}/>
    </Grid>
</Grid>


## Problem and Design Overview

Many people will agree that public speaking is terrifying. It is a daunting task that people are faced with at some point (or many points) in their lives. Despite how difficult it is and how often we are required to do it, it seems like there are not many ways to get feedback and know audience comprehension besides simply asking someone afterwards. Are there better or more accessible ways for people of all ages to improve their public speaking?

To solve this problem, Clark is a cross platform software focused on allowing the presenter to get real time feedback and the opportunity to review their presentation afterwards. This includes the ability to record presentations through the camera installed, review past recordings, as well as collect data on audience comprehension throughout the presentation in which the presenter can reflect back on. The hardware component is paired with a tablet screen that can display time left, submitted questions by the audience, or display emotional support messages. Clark will sit in front of the presenter for easy visibility and to monitor their presentation. This data is synced with the presenter’s phone app and combined with the feedback received through the audience app to give a comprehensive overview of the presentation.

## Design Research Process and Key Insights
To tackle our problem, we decided to try to understand the magnitude of the problem first and conducted a series of interviews with students and faculty members who frequently presented in front of multiple people. We chose people who regularly gave speeches to learn what aspects helped them succeed and where we could possibly help them as well as those inexperienced in public speaking, and focused on stakeholders from UW as they were easily accessible. These included three students - a fraternity leader, a Ph.D student with extensive TA experiences, and a Business student - as well as a communications professor teaching public speaking courses. We created a list of open-ended questions to ask each participant, which was updated after each interview, and conducted our interviews with a single note-taker and facilitator. We chose interviews as our primary research method as we felt that there were many factors that would make someone a good public speaker, and we needed to learn from the experiences of our stakeholders themselves.

### Delivery analysis:
We started our idea under the assumption that presenters want to learn more about statistics of their delivery: eye contact, number of filler words, pacing, words per minute, etc. This is because we started the project thinking about self-tracking, and these are statistics we can easily track. However, as we interviewed many participants, many of whom are great public speakers, we learned that they are more interested in connecting with the audience, adapting to the situation, and thinking fast on their feet. Moreover, we interviewed a public speaking professor. He conveyed to us that “many engineers try to solve a problem that doesn’t need to be solved,” namely tracking how many times someone used “um” because “even saying ‘um’ is not a problem.” We learned from him that the biggest problem with public speaking is that one speech structure does not fit all, and each occasion calls for different ways of presenting. From then on, our team decided to focus on helping the presenter receive feedback from the audience and connect with them to help the presenter improve. In our SmartWatch design, we incorporate buzzing for the audience to indicate interest/confusion real-time for the presenter to understand the audience’s reactions. In the Social app, we provide a platform for presenters to connect with other presenters with similar backgrounds/goals to practice together so that they can give more relevant feedback for their specific topics. In our Clark the robot design, we incorporated recording and emotional recognition (which we will edit later on) for the presenter to review after a presentation.

### Emotion analysis:
Part of the problem we want to address is how the presenter can better record and analyze the impact of their presentation on the audience. From interviews, we learned that presenters’ common goals are to connect with the audience. However, because of anxiety and lack of experience, the presenter often cannot clearly analyze the audience’s reaction when they’re presenting. Therefore, our original idea is to use Clark to record the audience during the presentation and analyze their reaction using artificial intelligence. However, through further critiques, we learned that facial emotion recognition is unreliable and biased. It often works ineffectively for people of color, for instance. Another design of ours, the SmartWatch, doesn’t use emotional recognition to receive feedback, and instead, it buzzes when the audience indicates interest or confusion. The participants we interviewed gave feedback that the buzzing can induce anxiety. Moreover, it is a distraction. Therefore, we decided to choose the Clark design, remove the emotional recognition aspect, and opt for personal written feedback directly from the audience.

### Importance of Speech Content:
One insight from our interviews that we hadn’t focused on previously was the significance of having good content within a speech. The communications professor from our interviews had emphasized that hitting all points within a rubric of main points or ideas was more important than the delivery of a speech, stating that “20% of a good speech is delivery. 80% is the actual content of the speech.” Thus, when we considered possible solutions and designs, we contemplated adding functions to help the speaker remember their key points of their speeches, or displaying the actual script itself. This was one of the main tasks we attempted to undertake with our mobile game and social media application design, where users can ensure key points are addressed within a speech. Though we decided to proceed with our Clark design due to the potential distractions of reading a script from a mobile device, we had provided options via customizable widgets for users to remember the main points of their presentations.

## Iterative Design Process and Key Insights

Our iterative design process was heavily centered around usability testing in order to identify areas of our paper prototype that functioned properly, and likewise areas that were difficult or unusable. The goal here was to capitalize on favorable design choices while making adjustments to weaker areas to slowly bring Clark towards a design that presenters could find beneficial. In order for this to happen, we needed our participants to have a smooth and seamless experience with our paper prototype. On our side of the usability testing process, this was achieved via 5 key roles: the Presenter Operator (Clark + App), the Audience Operator (Audience UI), a Facilitator, and two Notetakers.

Our design focus was ensuring that presenters could easily interact with the Clark app and use it to give effective presentations whilst connecting with their audience. Thus, the tasks given to the presenters were to prepare for a presentation, give a presentation, and view the recording of a previous presentation. Additionally, we tasked the audience with interacting via their side of the Clark interface because we wanted to make sure that audience members were able to meaningfully communicate their content understanding to the presenter.

Through high repetition of usability testing and prototype adjustments, we were able to flush out a solid paper prototype.

export const paperPrototypeItems = [
    {
        img: image1,
        title: 'Paper Prototype 1',
        rows: 1,
        cols: 1,
    },
    {
        img: image2,
        title: 'Paper Prototype 2',
        rows: 1,
        cols: 1,
    },
    {
        img: image3,
        title: 'Paper Prototype 3',
        rows: 2,
        cols: 2,
    },
];


<ImageList>
    {paperPrototypeItems.map((item) => (
        <ImageListItem key={item.img} cols={item.cols} rows={item.rows}>
            <img
                src={`${item.img}`}
                srcSet={`${item.img}`}
                alt={item.title}
                loading="lazy"
            />
        </ImageListItem>
    ))}
</ImageList>


### Improving Edit Clark Option
<Grid container spacing={2}>
    <Grid item xs={6} md={8}>
        One area that was fleshed out thoroughly during usability testing was our option to edit Clark’s display screen. For instance in initial tests, it was not clear to a participant that they could edit Clark’s screen by going to settings and appearances, or when they got there what to do. Because the presenter’s ability to customize Clark to best suit their needs is important to us, we added an additional button on the home screen that directly goes to the edit clark screen. We also added text instructing the participant to move widgets to the representation of Clark’s screen. Some participants wanted a higher level of customization to be able to drag individual components to specific locations, while others did not mind the default layout of Clark, so we also included the option of presets.
    </Grid>
    <Grid item xs={6} md={4}>
        <img
            src={`${image4}?auto=format`}
            width="100%"
            alt="Paper Prototype 4"
            loading="lazy"
        />
    </Grid>
</Grid>

### Improving Audience Feedback
<Grid container spacing={2}>
    <Grid item xs={6} md={8}>
        Initially, audience members are able to do two things: indicate understanding, and ask questions. While the audience interface is intended to be simple, we received a lot of feedback regarding the function that allowed audience members to ask questions throughout the presentation. Many participants felt that there ought to be a way for them to view questions asked by other audience members, as well as vote on the ones they felt were particularly good questions. This insight emerged when we prompted participants to ask a question, at which point, many of them wondered if a similar question had already been asked. Some direct quotes are “I wonder if anyone else is confused about this” and “Is there a way to see if someone has already asked this question?”. We iterated upon this design by adding a panel to allow audience members to view and vote on questions:
    </Grid>
    <Grid item xs={6} md={4}>
        <img
            src={`${image5}?auto=format`}
            width="100%"
            alt="Paper Prototype 5"
            loading="lazy"
        />
    </Grid>
</Grid>


### Improving Accessibility
<Grid container spacing={2}>
    <Grid item xs={6} md={8}>
        As we worked on our paper prototype, we referenced commonly used apps and interfaces. In addition to things like changing text size, we found that iPhones also offered the option to “differentiate without color”. One team member also pointed out that our prototype assumes that the user reads English. Because we wanted this to be accessible to people who spoke other languages, we also included the option to change the language the presenter’s app was in.
    </Grid>
    <Grid item xs={6} md={4}>
        <img
            src={`${image6}?auto=format`}
            width="100%"
            alt="Paper Prototype 6"
            loading="lazy"
        />
    </Grid>
</Grid>


## Resulting Design
Some critical aspects of our designs are in our audience UI and presenter app. The presenter’s goal is to record and save a presentation, and look back at the recording and interest levels. We implemented a QR code and unique url for the presenter to give to the audience to sign in to the feedback platform. For the audience, they can submit questions and indicate interest with a toggle. In the recording, the presenter can see timestamps of how the interest levels progressed, as well as the time questions come in.

### Task 1: Getting feedback during the presentation




#### Step 1:
The presenter logs in/sign up through the app.

export const task1Step1Images = [
    {
        img: task1Step1Image1,
        title: 'task1Step1Image1',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step1Image2,
        title: 'task1Step1Image2',
        rows: 1,
        cols: 1,
    },
];

<ImageList>
    {task1Step1Images.map((item) => (
        <ImageListItem key={item.img} cols={item.cols} rows={item.rows}>
            <img
                src={`${item.img}`}
                srcSet={`${item.img}`}
                alt={item.title}
                loading="lazy"
            />
        </ImageListItem>
    ))}
</ImageList>

#### Step 2:
The presenter shares a QR code (img 1) with the audience so they can access the presentation feedback platform (img 2) on their phone. The presenter clicks Test Audio/Video to access a preview (img 3). The presenter clicks on Edit Clark to add/remove widgets from Clark (img 4, img 5). The presenter clicks Start to start presentation and recording.

export const task1Step2Images = [
    {
        img: task1Step2Image1,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step2Image2,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step2Image3,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step2Image4,
        title: 'Alt',
        rows: 1,
        cols: 3,
    },
];

<ImageList cols={3}>
    {task1Step2Images.map((item) => (
        <ImageListItem key={item.img} cols={item.cols} rows={item.rows}>
            <img
                src={`${item.img}`}
                srcSet={`${item.img}`}
                alt={item.title}
                loading="lazy"
            />
        </ImageListItem>
    ))}
</ImageList>

#### Step 3:
Once presentation starts, the presenter app shows Stop button to stop presentation (img 1). The audience platform allows submissions for questions (img 2, img 4). Upon submitting a question, a check mark indicates the question submitted successfully (img 5). The question shows up on Clark (img 8). The audience also has the option to look at other questions that have been submitted and upvote the ones they agree with (img 6, img 7). To express general confusion not tied to a question, the audience also has a toggle to indicate confusion (img 2, img 3).

export const task1Step3Images = [
    {
        img: task1Step3Image1,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step3Image2,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step3Image3,
        title: 'Alt',
        rows: 1,
        cols: 2,
    },
    {
        img: task1Step3Image4,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
    {
        img: task1Step3Image5,
        title: 'Alt',
        rows: 1,
        cols: 4,
    },
];

<ImageList cols={4}>
    {task1Step3Images.map((item) => (
        <ImageListItem key={item.img} cols={item.cols} rows={item.rows}>
            <img
                src={`${item.img}`}
                srcSet={`${item.img}`}
                alt={item.title}
                loading="lazy"
            />
        </ImageListItem>
    ))}
</ImageList>


#### Step 4:

The presenter ends the recording and saves it with a particular name (with a character limit) (img 1). The screens for each audience member that joined displays a thank you page (img 2).

export const task1Step4Images = [
    {
        img: task1Step4Image1,
        title: 'Alt',
        rows: 1,
        cols: 2,
    },
    {
        img: task1Step4Image2,
        title: 'Alt',
        rows: 1,
        cols: 1,
    },
];

<ImageList cols={3}>
    {task1Step4Images.map((item) => (
        <ImageListItem key={item.img} cols={item.cols} rows={item.rows}>
            <img
                src={`${item.img}`}
                srcSet={`${item.img}`}
                alt={item.title}
                loading="lazy"
            />
        </ImageListItem>
    ))}
</ImageList>
### Task 2: Accessing the interest / confusion level of the audience after the presentation

#### Step 1:

The presenter logs in/sign up through the app.

#### Step 2:

The presenter heads to the recordings tab and selects the recording they wish to view (img 1), and uses the slider to find where the audience asked the most questions and where a large portion of the audience understands or doesn’t understand the content (img 2).

<img
    src={task2Step2Image1}
    alt="alt"
    width="100%"
    loading="lazy"
/>



